{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import pyedflib\n",
    "except:\n",
    "    !pip install pyedflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TAACHUP2\\Miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings \n",
    "import random\n",
    "import collections\n",
    "from numpy.random import seed\n",
    "import torch\n",
    "import torch.utils as utils\n",
    "import torch.utils.data as data\n",
    "from os import path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ','P7-T7','T7-FT9','FT9-FT10','FT10-T8']\n",
    "\n",
    "#for i in range(23):\n",
    "#file2 = pyedflib.EdfReader('chb12_06.edf')\n",
    "#for channel in channels:\n",
    "    #file2.readEdfFile(channel)\n",
    "#signal_labels = file2.getSignalLabels()\n",
    "#print(signal_labels)\n",
    "#n = file2.signals_in_file\n",
    "dat = readEdfFile('chb12_06.edf', channels)\n",
    "\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pathDataSet = 'CHB-MIT/'\n",
    "processed_data_path = 'CHB-MIT_processed/'\n",
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ','P7-T7','T7-FT9','FT9-FT10','FT10-T8']\n",
    "patients = [ \"01\", \"02\"]\n",
    "            #, \"09\", \"10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSummaryPatient(index):\n",
    "  f = open(pathDataSet+'chb'+patients[index]+'/chb'+patients[index]+'-summary.txt', 'r') \n",
    "  parent = pathDataSet+'chb'+patients[index]+'/'\n",
    "  return f, parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readEdfFile(pathToFile, channels):\n",
    "    f = pyedflib.EdfReader(pathToFile)\n",
    "    n = f.signals_in_file\n",
    "    #print(n)\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sigbufs = np.zeros((f.getNSamples()[0],n))\n",
    "    for i in np.arange(n): \n",
    "        sigbufs[:,i] = f.readSignal(i)\n",
    "    #sigbufs[:, n]= 0.0\n",
    "    df =  pd.DataFrame(data = sigbufs, columns = signal_labels)\n",
    "    #print(df.shape)\n",
    "    df = df.loc[:, channels]\n",
    "    #print(df.shape)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    #print(df.shape)\n",
    "    f._close()\n",
    "    del f\n",
    "    data = df.values\n",
    "    #data_numpy = data.to_numpy()\n",
    "    return np.transpose(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    3\n",
      "0  1  0.0\n",
      "1  1  0.0\n",
      "2  1  0.0\n"
     ]
    }
   ],
   "source": [
    "#signal_label1 = ['2', '1']\n",
    "signal_labels = ['3','4','2', '6','1']\n",
    "#sigbufs = np.zeros((2,2))\n",
    "sigbufs1 = np.zeros((3,5))\n",
    "df =  pd.DataFrame(data = sigbufs1, columns = signal_labels)\n",
    "df.iloc[:,4]=1\n",
    "#print(df)\n",
    "#df1 =  pd.DataFrame(data = sigbufs, columns = signal_label1)\n",
    "cha = ['1','3']\n",
    "#df1 = df1.loc[:, cha]\n",
    "df = df.loc[:, cha]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seizureNumpyMatrixGenerate(secSt, secEn, name_F, parent, index):\n",
    "  file1 = pyedflib.EdfReader(parent+name_F)\n",
    "  n = file1.signals_in_file\n",
    "  rate =256\n",
    "  col = file1.getNSamples()[0]\n",
    "  # print(n)\n",
    "  #signal_labels = file1.getSignalLabels()\n",
    "  #signal_headers = file1.getSignalHeaders()\n",
    "  #rate = signal_headers[0]['sample_rate']\n",
    "  dur = file1.getFileDuration()\n",
    "  #print(f'Duration of this trial {dur}')\n",
    "  file1._close()\n",
    "  del file1\n",
    "  x = np.zeros((n, col))\n",
    "  #for i in range(n):\n",
    "    #x[i,:] = file1.readSignal(i)\n",
    "  x = readEdfFile(parent+name_F, channels)\n",
    "    # print(x)\n",
    "    #label = file1.getLabel(i)\n",
    " \n",
    " \n",
    "  #x_filter = butter_bandpass_filter(x ,lowcut , highcut , fs , order = 5)\n",
    "  #a = os.getcwd()\n",
    "  folder_path= processed_data_path + 'chb'+ patients[index] + '/'\n",
    "  if os.path.isdir(processed_data_path) is not True:\n",
    "    os.makedirs(processed_data_path)\n",
    "  subfolder_path = folder_path + name_F.split('.')[0] + '/'\n",
    "  if os.path.isdir(subfolder_path) is not True:\n",
    "    os.makedirs(subfolder_path)\n",
    "    print(subfolder_path)\n",
    "    picnum = int(dur*rate/256)\n",
    "    #print(picnum)\n",
    "    num_seizure = 0\n",
    "    num_nonseizure = 0\n",
    "    for i in range(picnum):\n",
    "      img = x[:,i*256:(i+1)*256]\n",
    "      #img = (img - np.min(img))/(np.max(img) - np.min(img))\n",
    "      #Img = Image.fromarray(np.uint8(img))\n",
    "      if len(secSt) == 1:\n",
    "        if secSt[0] <= i+1 <= secEn[0]: #window size is 1sec\n",
    "            name = 'seizure'\n",
    "            num_seizure+=1\n",
    "        else:\n",
    "            name = 'nonseizure'\n",
    "            num_nonseizure +=1\n",
    "      elif len(secSt) == 2:\n",
    "        if secSt[0] <= i+1 <= secEn[0] or secSt[1] <= i+1 <= secEn[1]: #window size is 1sec\n",
    "            name = 'seizure'\n",
    "            num_seizure+=1\n",
    "        else:\n",
    "            name = 'nonseizure' \n",
    "            num_nonseizure +=1\n",
    "      elif len(secSt) == 3:\n",
    "        if secSt[0] <= i+1 <= secEn[0] or secSt[1] <= i+1 <= secEn[1] or secSt[2] <= i+1 <= secEn[2]: #window size is 1sec\n",
    "            name = 'seizure'\n",
    "            num_seizure+=1\n",
    "        else:\n",
    "            name = 'nonseizure'\n",
    "            num_nonseizure +=1\n",
    "      else: \n",
    "        if secSt[0] <= i+1 <= secEn[0] or secSt[1] <= i+1 <= secEn[1] or secSt[2] <= i+1 <= secEn[2] or secSt[3] <= i+1 <= secEn[3]:\n",
    "            name = 'seizure'\n",
    "            num_seizure+=1\n",
    "        else:\n",
    "            name = 'nonseizure'\n",
    "            num_nonseizure +=1\n",
    "          \n",
    "\n",
    "      if i+1 < 10:\n",
    "          filename = 'time_'+name+'_0000'+ str(i+1)\n",
    "      elif 10 <= i+1 < 100:\n",
    "          filename = 'time_'+name+'_000'+ str(i+1)\n",
    "      elif 100 <= i+1 < 1000:\n",
    "          filename = 'time_'+name+'_00'+ str(i+1)\n",
    "      elif 1000 <= i+1 < 10000:\n",
    "          filename = 'time_'+name+'_0'+ str(i+1)\n",
    "      else:\n",
    "          filename = 'time_'+name+'_'+ str(i+1)\n",
    "      if path.exists(subfolder_path+ filename+'.npy'):\n",
    "        continue\n",
    "      else:\n",
    "        np.save(subfolder_path + filename+'.npy', img)\n",
    "          #print('-')\n",
    "      \n",
    "  else:\n",
    "    print('folder already exists') \n",
    "\n",
    "  return (num_seizure, num_nonseizure, num_seizure+num_nonseizure, dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    \n",
    "    seizure_trials = {}\n",
    "    total_duration = 0\n",
    "    total_seizure = []\n",
    "    total_nonseizure = []\n",
    "    print(\"START \\n\")\n",
    "    for indexPatient in range(0, len(patients)):\n",
    "        seizure_num_per_patient = []\n",
    "        nonseizure_num_per_patient = []\n",
    "        values = []\n",
    "        key = 'chb'+patients[indexPatient]\n",
    "        #print(indexPatient)\n",
    "        f, parent = loadSummaryPatient(indexPatient)\n",
    "        line=f.readline()\n",
    "        #print(' i was here')\n",
    "        \n",
    "        while (line):\n",
    "            data=line.split(':')\n",
    "            #print(data)\n",
    "            if (data[0]==\"File Name\"):\n",
    "                name_F=data[1].strip()\n",
    "                \n",
    "                #print(name_F)\n",
    "                fileSt=f.readline().split(': ')[1]\n",
    "                # Sthr=fileSt.split(':')[0]\n",
    "                # #print(Sthr)\n",
    "                # Stmin=fileSt.split(':')[1]\n",
    "                # #print(Stmin)\n",
    "                # Stsec=fileSt.split(':')[2]\n",
    "                # #print(Stsec)\n",
    "                fileEn=f.readline().split(': ')[1]\n",
    "                # Enhr=fileEn.split(':')[0]\n",
    "                # #print(Enhr)\n",
    "                # Enmin=fileSt.split(':')[1]\n",
    "                # #print(Enmin)\n",
    "                # Ensec=fileSt.split(':')[2]\n",
    "                # #print(Ensec)\n",
    "                # trial_duration = ((int(Enhr) - int(Sthr))*3600 + (int(Enmin) - int(Stmin))*60 + (int(Ensec) - int(Stsec)))\n",
    "                \n",
    "                # print(trial_duration)\n",
    "                for i in range(1):\n",
    "                    line=f.readline()\n",
    "                secSt = []\n",
    "                secEn = []\n",
    "                for j in range(0, int(line.split(': ')[1])):\n",
    "                    if j==0:\n",
    "                        print(f'trial : {name_F}')\n",
    "                        value = name_F\n",
    "                        values.append(value)\n",
    "                                     \n",
    "                    secSt.append(int(f.readline().split(': ')[1].split(' ')[0]))\n",
    "                    #print(f'Start second of seizure {secSt}')\n",
    "                    secEn.append(int(f.readline().split(': ')[1].split(' ')[0]))\n",
    "                    #print(f'Start second of seizure {secEn}')\n",
    "                if int(line.split(': ')[1]) != 0:\n",
    "                    seizure_num_per_trial, nonseizure_num_per_trial, total_samples, dur = seizureNumpyMatrixGenerate(secSt, secEn, name_F, parent, indexPatient)   # creates numpy matrices for 1 s windows\n",
    "                    total_duration += dur\n",
    "                    print(f'No. of seizure samples : {seizure_num_per_trial}, No. of non-seizure samples : {nonseizure_num_per_trial}, Total no. of samples : {seizure_num_per_trial + nonseizure_num_per_trial}')\n",
    "                    #seizure_num_per_trial.append(num_seizure)\n",
    "                    #print(seizure_num_per_trial)\n",
    "                    #nonseizure_num_per_trial.append(num_nonseizure)\n",
    "                    #print(nonseizure_num_per_trial)\n",
    "                    seizure_num_per_patient.append(seizure_num_per_trial)\n",
    "                    nonseizure_num_per_patient.append(nonseizure_num_per_trial)\n",
    "            seizure_trials[key] = values\n",
    "            line=f.readline()\n",
    "        f.close()\n",
    "        \n",
    "        print(seizure_num_per_patient)\n",
    "        print(nonseizure_num_per_patient)\n",
    "        total_seizure.append(np.sum(seizure_num_per_patient))\n",
    "        print(total_seizure)\n",
    "        total_nonseizure.append(np.sum(nonseizure_num_per_patient))\n",
    "        print(total_nonseizure)\n",
    "    \n",
    "    print(\"END \\n\")\n",
    "    return seizure_trials, total_duration, np.sum(total_seizure), np.sum(total_nonseizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START \n",
      "\n",
      "trial : chb01_03.edf\n",
      "CHB-MIT_processed/chb01/chb01_03/\n",
      "No. of seizure samples : 41, No. of non-seizure samples : 3559, Total no. of samples : 3600\n",
      "trial : chb01_04.edf\n",
      "CHB-MIT_processed/chb01/chb01_04/\n",
      "No. of seizure samples : 28, No. of non-seizure samples : 3572, Total no. of samples : 3600\n",
      "trial : chb01_15.edf\n",
      "CHB-MIT_processed/chb01/chb01_15/\n",
      "No. of seizure samples : 41, No. of non-seizure samples : 3559, Total no. of samples : 3600\n",
      "trial : chb01_16.edf\n",
      "CHB-MIT_processed/chb01/chb01_16/\n",
      "No. of seizure samples : 52, No. of non-seizure samples : 3548, Total no. of samples : 3600\n",
      "trial : chb01_18.edf\n",
      "CHB-MIT_processed/chb01/chb01_18/\n",
      "No. of seizure samples : 91, No. of non-seizure samples : 3509, Total no. of samples : 3600\n",
      "trial : chb01_21.edf\n",
      "CHB-MIT_processed/chb01/chb01_21/\n",
      "No. of seizure samples : 94, No. of non-seizure samples : 3506, Total no. of samples : 3600\n",
      "trial : chb01_26.edf\n",
      "CHB-MIT_processed/chb01/chb01_26/\n",
      "No. of seizure samples : 102, No. of non-seizure samples : 2223, Total no. of samples : 2325\n",
      "[41, 28, 41, 52, 91, 94, 102]\n",
      "[3559, 3572, 3559, 3548, 3509, 3506, 2223]\n",
      "[449]\n",
      "[23476]\n",
      "trial : chb02_16.edf\n",
      "CHB-MIT_processed/chb02/chb02_16/\n",
      "No. of seizure samples : 83, No. of non-seizure samples : 876, Total no. of samples : 959\n",
      "trial : chb02_16+.edf\n",
      "CHB-MIT_processed/chb02/chb02_16+/\n",
      "No. of seizure samples : 82, No. of non-seizure samples : 3518, Total no. of samples : 3600\n",
      "trial : chb02_19.edf\n",
      "CHB-MIT_processed/chb02/chb02_19/\n",
      "No. of seizure samples : 10, No. of non-seizure samples : 3590, Total no. of samples : 3600\n",
      "[83, 82, 10]\n",
      "[876, 3518, 3590]\n",
      "[449, 175]\n",
      "[23476, 7984]\n",
      "END \n",
      "\n"
     ]
    }
   ],
   "source": [
    "seizure_trials, total_duration, total_duration_seizure, total_duration_nonseizure = createDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chb01': ['chb01_03.edf', 'chb01_04.edf', 'chb01_15.edf', 'chb01_16.edf', 'chb01_18.edf', 'chb01_21.edf', 'chb01_26.edf'], 'chb02': ['chb02_16.edf', 'chb02_16+.edf', 'chb02_19.edf']} 2 32084 624 31460\n"
     ]
    }
   ],
   "source": [
    "print(seizure_trials,len(seizure_trials), total_duration, total_duration_seizure, total_duration_nonseizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_trials = [ 'chb01_03.edf', 'chb01_04.edf', 'chb01_15.edf', 'chb01_16.edf', 'chb01_18.edf', 'chb01_21.edf', 'chb01_26.edf', 'chb02_16.edf', 'chb02_16+.edf', 'chb02_19.edf', 'chb07_12.edf', 'chb07_13.edf', 'chb07_19.edf', 'chb08_02.edf', 'chb08_05.edf', 'chb08_11.edf', 'chb08_13.edf', 'chb08_21.edf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_4chars(x): #function to sort the numbers in filename so that they can be grouped sequentially\n",
    "  #print(x[-4])\n",
    "  return(x[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(seizure_trials, folder_path, window_size, total_duration):\n",
    "  features = np.zeros(((int(total_duration/window_size)),22,256*window_size))\n",
    "  labels = np.zeros((int(total_duration/window_size)),dtype=int)\n",
    "  i = 0 #the feature index\n",
    " \n",
    "  for trial in seizure_trials:\n",
    "      name = sorted(os.listdir(folder_path + trial.split('.')[0]), key= last_4chars)\n",
    "      #print(name)\n",
    "      #for window in (range(0, int(total_duration/len(seizure_trials)), window_size)):\n",
    "      for window in (range(0, int(len(name)/window_size), window_size)):\n",
    "          #print(window)\n",
    "          seizure = 0\n",
    "          non_seizure = 0\n",
    "          feature_prep = np.zeros((22,256*window_size))\n",
    "          for j in range(window_size):\n",
    "              if '_seizure_' in name[window+j]:\n",
    "                  #print(name[window+j])\n",
    "                  seizure+=1\n",
    "                  #print('seizure no.', seizure)\n",
    "                  #print('hi')\n",
    "                  feature_prep[0:22,j*256:((j+1)*256)] = np.array(np.load(folder_path + trial.split('.')[0]+'/'+ name[window+j]))[0:22,0:256]\n",
    "              elif '_nonseizure_' in name[window+j]:\n",
    "                  #print(name[window+j])\n",
    "                  non_seizure+=1\n",
    "                  #print('nonseizure no.', non_seizure)\n",
    "                  #print('nohi')\n",
    "                  feature_prep[0:22,j*256:((j+1)*256)] = np.array(np.load(folder_path + trial.split('.')[0]+'/'+ name[window+j]))[0:22,0:256]\n",
    "                  #print(feature_prep.shape)\n",
    "          #print(feature_prep.shape)\n",
    "          feature_prep_normalized = (feature_prep - np.min(feature_prep)) / (np.max(feature_prep) -np.min(feature_prep))\n",
    "          #print('seizure no.', seizure)\n",
    "          #print('nonseizure no.', non_seizure)\n",
    "          if seizure > non_seizure:\n",
    "              #print('label should be 1')\n",
    "              features[i] = feature_prep_normalized\n",
    "              labels[i] = 1\n",
    "              #print(features[i])\n",
    "              #print(labels[i])\n",
    "          else:\n",
    "              #print('label should be 0')\n",
    "              features[i] = feature_prep_normalized\n",
    "              labels[i] = 0\n",
    "              #print(features[i])\n",
    "              #print(labels[i])\n",
    "          #print('================================')\n",
    "          i = i+1\n",
    "         # print(features)\n",
    "         # print(features.shape)\n",
    "          \n",
    "   #       print(i)\n",
    "                  \n",
    "\n",
    "  #print(i)\n",
    "    #print(features)\n",
    "    #print(labels)\n",
    "    #print(np.expand_dims(np.array(features), axis=3).shape)\n",
    "    #print(labels.shape)\n",
    "  with open('features_train_1_2.npy', 'wb') as f:\n",
    "    np.save(f, features)\n",
    "  f.close\n",
    "  \n",
    "  with open('labels_train_1_2.npy', 'wb') as f:\n",
    "    np.save(f, labels)\n",
    "  f.close\n",
    "  \n",
    "  #dataloader = utils.data.DataLoader(dataset)\n",
    "    #dataset = np.stack((features,labels), axis = 0)\n",
    "  #print(dataset.shape)\n",
    "\n",
    "  return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chb04_05.edf', 'chb04_08.edf', 'chb04_28.edf']\n",
      "['chb05_06.edf', 'chb05_13.edf', 'chb05_16.edf', 'chb05_17.edf', 'chb05_22.edf']\n"
     ]
    }
   ],
   "source": [
    "seizure_trials_train = seizure_trials                 \n",
    "for index in range(len(seizure_trials)):\n",
    "#total_duration = 3600*len(seizure_trials_train)\n",
    "    key_value_pair = list(seizure_trials_train.items())[index]\n",
    "    print(key_value_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seizure_trials_train = ['chb08_02.edf', 'chb08_05.edf', 'chb08_11.edf', 'chb08_13.edf']\n",
    "                  #, 'chb08_21.edf']\n",
    "seizure_trials_train = seizure_trials                 \n",
    "window_size = [1,2,4,8,10]\n",
    "#index = 0\n",
    "for index in range(len(seizure_trials)):\n",
    "#total_duration = 3600*len(seizure_trials_train)\n",
    "    folder_path= processed_data_path + 'chb'+ patients[index] + '/'\n",
    "    key_value_pair = list(seizure_trials_train.items())[index]\n",
    "    create_feature_matrix(key_value_pair[1], folder_path, window_size[2], total_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chb08_13.edf\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [60], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m total_duration \u001b[39m=\u001b[39m \u001b[39m3600\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(seizure_trials_test)\n\u001b[0;32m      6\u001b[0m folder_path\u001b[39m=\u001b[39m processed_data_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mchb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m patients[index] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m create_feature_matrix(seizure_trials, folder_path, window_size[\u001b[39m2\u001b[39;49m], total_duration)\n",
      "Cell \u001b[1;32mIn [45], line 15\u001b[0m, in \u001b[0;36mcreate_feature_matrix\u001b[1;34m(seizure_trials, folder_path, window_size, total_duration)\u001b[0m\n\u001b[0;32m     13\u001b[0m feature_prep \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m23\u001b[39m,\u001b[39m256\u001b[39m\u001b[39m*\u001b[39mwindow_size))\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(window_size):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_seizure_\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m name[window\u001b[39m+\u001b[39;49mj]:\n\u001b[0;32m     16\u001b[0m         \u001b[39m#print(name[window+j])\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         seizure\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     18\u001b[0m         \u001b[39m#print('seizure no.', seizure)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         \u001b[39m#print('hi')\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "seizure_trials_test = seizure_trials_train[-1]\n",
    "print(seizure_trials_test)\n",
    "window_size = [1,2,4,8,10]\n",
    "index = 0\n",
    "total_duration = 3600*len(seizure_trials_test)\n",
    "folder_path= processed_data_path + 'chb'+ patients[index] + '/'\n",
    "create_feature_matrix(seizure_trials, folder_path, window_size[2], total_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape  (8021, 22, 1024)\n",
      "labels shape (8021,)\n",
      "features tensorshape  torch.Size([8021, 1, 22, 1024])\n"
     ]
    }
   ],
   "source": [
    "features_train = np.load('features_train_1_2.npy')\n",
    "labels_train = np.load('labels_train_1_2.npy')\n",
    "\n",
    "print('features shape ', features_train.shape)\n",
    "    # print('feature 0', features[0])\n",
    "print('labels shape', labels_train.shape)\n",
    "  #for i in range(len(labels)):\n",
    "    #print(labels[i])\n",
    "\n",
    "feature_tensor = torch.Tensor(features_train)\n",
    "feature_tensor = feature_tensor.unsqueeze(dim = 1)\n",
    "print('features tensorshape ', feature_tensor.shape)\n",
    "label_tensor = torch.Tensor(labels_train)\n",
    "\n",
    "dataset = utils.data.TensorDataset(feature_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape  (900, 23, 1024)\n",
      "labels shape (900,)\n",
      "features tensorshape  torch.Size([900, 1, 23, 1024])\n"
     ]
    }
   ],
   "source": [
    "features_test = np.load('features_test.npy')\n",
    "labels_test = np.load('labels_test.npy')\n",
    "\n",
    "print('features shape ', features_test.shape)\n",
    "    # print('feature 0', features[0])\n",
    "print('labels shape', labels_test.shape)\n",
    "  #for i in range(len(labels)):\n",
    "    #print(labels[i])\n",
    "\n",
    "feature_tensor = torch.Tensor(features_test)\n",
    "feature_tensor = feature_tensor.unsqueeze(dim = 1)\n",
    "print('features tensorshape ', feature_tensor.shape)\n",
    "label_tensor = torch.Tensor(labels_test)\n",
    "\n",
    "test_dataset = utils.data.TensorDataset(feature_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7*len(dataset))\n",
    "val_size = int(0.2*len(dataset))\n",
    "test_size = int(0.1*len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#dataset = np.load(path+'preprocessed_data')\n",
    "#train_dataset, val_dataset, test_dataset = data.random_split(dataset,\n",
    "                                               #[train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 900, 450)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "c_train = 0\n",
    "for i in range(len(train_dataset)):\n",
    "  _, label = train_dataset[i][0], train_dataset[i][1]\n",
    "  #print(f\"Image tensor:\\n{img}\")\n",
    "  #print(f\"Image shape: {img.shape}\")\n",
    "  #print(f\"Image datatype: {img.dtype}\")\n",
    "  if label == 1.0:\n",
    "    c_train +=1\n",
    "    #print(f\"Image label: {label}\")\n",
    "print(c_train)\n",
    "  #print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "c_val = 0\n",
    "for i in range(len(val_dataset)):\n",
    "  _, label = val_dataset[i][0], val_dataset[i][1]\n",
    "  #print(f\"Image tensor:\\n{img}\")\n",
    "  #print(f\"Image shape: {img.shape}\")\n",
    "  #print(f\"Image datatype: {img.dtype}\")\n",
    "  if label == 1.0:\n",
    "    #print(f\"Image label: {label}\")\n",
    "    c_val +=1\n",
    "  #print(f\"Label datatype: {type(label)}\")\n",
    "print(c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "c_test = 0\n",
    "for i in range(len(test_dataset)):\n",
    "  _, label = test_dataset[i][0], test_dataset[i][1]\n",
    "  #print(f\"Image tensor:\\n{img}\")\n",
    "  #print(f\"Image shape: {img.shape}\")\n",
    "  #print(f\"Image datatype: {img.dtype}\")\n",
    "  if label == 1.0:\n",
    "    c_test +=1\n",
    "   # print(f\"Image label: {label}\")\n",
    "print(c_test)\n",
    "  #print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Random Sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "class_samples_count = [13745, 655]\n",
    "weight = [1/ class_samples_count[0], 1/class_samples_count[1]]\n",
    "#weight[0] = float(1/13745)\n",
    "#weight[1] = float(1/655)\n",
    "#samples_weight = [1/13745, 1/655]\n",
    "#samples_weight = [1, 100]\n",
    "samples_weight = np.array([weight[t] for t in range(2)])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "#print(samples_weight)\n",
    "sampler_train = WeightedRandomSampler(weights = samples_weight, num_samples = len(train_dataset), replacement=True)\n",
    "\n",
    "sampler_val = WeightedRandomSampler(samples_weight, len(val_dataset), replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, # use custom created train Dataset\n",
    "                                     #sampler = sampler_train,\n",
    "                                     batch_size=32, # how many samples per batch?\n",
    "                                     num_workers=4, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, # use custom created test Dataset\n",
    "                                    #sampler = sampler_val,\n",
    "                                    batch_size=32, \n",
    "                                    num_workers=4, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, # use custom created test Dataset\n",
    "                                    #sampler = sampler,\n",
    "                                    batch_size=32, \n",
    "                                    num_workers=4, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "# Get image and label from custom DataLoader\n",
    "\n",
    "# for i in range(len(train_dataloader)):\n",
    "#   img_custom_val, label_val = next(iter(train_dataloader))\n",
    "#   #print(img_custom_val.shape)\n",
    "#   if label_val.any == 1.0:\n",
    "#     print(label_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(1, 8), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(4, 16, kernel_size=(1, 16), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(16, 16, kernel_size=(1, 8), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(16, 16, kernel_size=(16, 1), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv2d(16, 16, kernel_size=(16, 1), stride=(1, 1), padding=same)\n",
      "  (pool5): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool6): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "  (fcn): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.randn(3,1,22,1024).to(device)\n",
    "#print(x.shape)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(1,8), stride = (1,1), padding = 'same')\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,8), stride=(1,8))\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=(1,16), stride = (1,1), padding = 'same')\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1,4), stride=(1,4))\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,8), stride = (1,1), padding = 'same')\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(1,4), stride=(1,4))\n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(16,1), stride = (1,1), padding = 'same')\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(4,1), stride=(4,1))\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(16,1), stride = (1,1), padding = 'same')\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=(4,1), stride=(4,1))\n",
    "        self.pool6 = nn.AvgPool2d(kernel_size=(1,int(size/128)), stride=(1,int(size/128)))\n",
    "        self.fcn = nn.Linear(16, 2)\n",
    "        #self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        #print('conv1 and relu', x.shape)\n",
    "        x= self.pool1(x)\n",
    "        #print('pool1', x.shape)\n",
    "        x=F.relu(self.conv2(x))\n",
    "        #print('conv2 and relu',x.shape)\n",
    "        x= self.pool2(x)\n",
    "        #print('pool2', x.shape)\n",
    "        x=F.relu(self.conv3(x))\n",
    "        #print('conv3 and relu', x.shape)\n",
    "        x= self.pool3(x)\n",
    "        #print('pool3', x.shape)\n",
    "        x=F.relu(self.conv4(x))\n",
    "        #print('conv4 and relu', x.shape)\n",
    "        x= self.pool4(x)\n",
    "        #print('pool4', x.shape)\n",
    "        x=F.relu(self.conv5(x))\n",
    "        #print('conv5 and relu', x.shape)\n",
    "        x= self.pool5(x)\n",
    "        #print('pool5', x.shape)\n",
    "        x= self.pool6(x)\n",
    "        #print('global avg pooling', x.shape)\n",
    "        x = torch.squeeze(x,2)\n",
    "        #print('1st squeezed x', x.shape)\n",
    "        x = torch.squeeze(x,2)\n",
    "        #print('2nd squeezed x', x.shape)\n",
    "        x= self.fcn(x)\n",
    "        #print('fcn', x.shape)\n",
    "        #x= self.sigmoid(x)\n",
    "        #print('final prediction', x.shape)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "#model_1 = CNN(256).to(device)\n",
    "#model_2 = CNN(512).to(device)\n",
    "model = CNN(1024).to(device)\n",
    "output = model(x.to(device))\n",
    "print(model)\n",
    "print(output.shape)\n",
    "#output = model(img_custom_test.to(device))\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "     -------------------------------------- 529.7/529.7 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\taachup2\\miniconda3\\lib\\site-packages (from torchmetrics) (1.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\taachup2\\miniconda3\\lib\\site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\users\\taachup2\\miniconda3\\lib\\site-packages (from torchmetrics) (1.13.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\taachup2\\miniconda3\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\taachup2\\miniconda3\\lib\\site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "Installing collected packages: torchmetrics\n",
      "Successfully installed torchmetrics-0.10.3\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import torchmetrics\n",
    "except:\n",
    "    !pip install torchmetrics \n",
    "    import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc, train_avg_loss, train_avg_acc = 0, 0, 0, 0, \n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X_train, y_train) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X_train = X_train.to(device)\n",
    "        #print(X_train.shape)\n",
    "        y_train = y_train.type(torch.LongTensor) \n",
    "        y_train = y_train.to(device)\n",
    "        #print(y_train.shape)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_logits_train = model(X_train)\n",
    "        #print(y_logits_train.shape)\n",
    "        y_prob_train = torch.softmax(y_logits_train, dim=1)\n",
    "        #print(y_logits_train.shape)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_prob_train, y_train)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_train = torch.argmax(torch.softmax(y_logits_train, dim=1), dim=1)\n",
    "        train_acc += (y_pred_train == y_train).sum().item()/len(y_logits_train)\n",
    "\n",
    "        # Calculate and accumulate specificity\n",
    "        # specificity = Specificity(average='micro', num_classes=2).to(device)\n",
    "        # train_spec += specificity(y_pred_train, y_train)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_avg_loss = train_loss / len(dataloader)\n",
    "    train_avg_acc = train_acc / len(dataloader)\n",
    "    #train_avg_spec = train_spec / len(dataloader)\n",
    "    return train_avg_loss, train_avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # Setup test loss and test accuracy values\n",
    "    val_loss, val_acc, val_avg_loss, val_avg_acc = 0, 0, 0, 0\n",
    "    # for i in range(len(dataloader)):\n",
    "    #     _, label_val = next(iter(dataloader))\n",
    "    #     print(label_val)\n",
    "    #print(dataloader.shape)\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X_val, y_val) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X_val = X_val.to(device)\n",
    "            #print('shape of x_val', X_val.shape)\n",
    "            y_val = y_val.type(torch.LongTensor) \n",
    "            y_val = y_val.to(device)\n",
    "            y_true.append(y_val)\n",
    "            # 1. Forward pass\n",
    "            y_logits_val = model(X_val)\n",
    "            #print('y_val shape',y_val.shape)\n",
    "            #print('y_val_logits shape', y_logits_val.shape)\n",
    "            y_prob_val = torch.softmax(y_logits_val, dim=1)\n",
    "            #print('y_val_softmax shape', y_prob_val.shape)\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(y_prob_val, y_val)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            y_pred_val = torch.argmax(torch.softmax(y_logits_val, dim=1), dim=1)\n",
    "            val_acc += ((y_pred_val == y_val).sum().item()/len(y_logits_val))\n",
    "            y_pred.append(y_pred_val)\n",
    "            # Calculate and accumulate specificity\n",
    "            # specificity = Specificity(average='micro', num_classes=2).to(device)\n",
    "            # val_spec += specificity(y_pred_val, y_val)   \n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    val_avg_loss = val_loss / len(dataloader)\n",
    "    val_avg_acc = val_acc / len(dataloader)\n",
    "    # val_avg_spec = val_spec / len(dataloader)\n",
    "    return val_avg_loss, val_avg_acc, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2399,  1.2119, -0.4352], requires_grad=True) torch.Size([3])\n",
      "tensor([1., 1., 1.]) torch.Size([3])\n",
      "tensor([0.4403, 0.7706, 0.3929], grad_fn=<SigmoidBackward0>) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    " m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "print(input, input.shape)\n",
    "target = torch.empty(3).random_(2)\n",
    "print(target, target.shape)\n",
    "output = loss(m(input), target)\n",
    "print(m(input), (m(input)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          val_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(weight=torch.FloatTensor([1.0,23.0])),\n",
    "          epochs: int = 10):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_spec\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_spec\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_avg_loss, train_avg_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "\n",
    "        val_avg_loss, val_avg_acc, y_true, y_pred = val_step(model=model,\n",
    "            dataloader=val_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_avg_loss:.4f} | \"\n",
    "            f\"train_acc: {train_avg_acc:.4f} | \"\n",
    "           # f\"train_spec: {train_avg_spec:.4f} \"\n",
    "            f\"val_loss: {val_avg_loss:.4f} | \"\n",
    "            f\"val_acc: {val_avg_acc:.4f} |\"\n",
    "         #   f\"val_spec: {val_avg_spec:.4f} \"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_avg_loss)\n",
    "        results[\"train_acc\"].append(train_avg_acc)\n",
    "     #   results[\"train_spec\"].append(train_avg_spec)\n",
    "        results[\"val_loss\"].append(val_avg_loss)\n",
    "        results[\"val_acc\"].append(val_avg_acc)\n",
    "     #   results[\"val_spec\"].append(val_avg_spec)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch: 1 | train_loss: 0.3574 | train_acc: 0.9338 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 18.225 seconds\n",
      "Fold 2\n",
      "Epoch: 1 | train_loss: 0.3432 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 17.259 seconds\n",
      "Fold 3\n",
      "Epoch: 1 | train_loss: 0.3360 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 18.086 seconds\n",
      "Fold 4\n",
      "Epoch: 1 | train_loss: 0.3398 | train_acc: 0.9779 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 17.442 seconds\n",
      "Fold 5\n",
      "Epoch: 1 | train_loss: 0.3413 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 17.906 seconds\n",
      "Fold 6\n",
      "Epoch: 1 | train_loss: 0.3442 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 17.547 seconds\n",
      "Fold 7\n",
      "Epoch: 1 | train_loss: 0.3349 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 17.259 seconds\n",
      "Fold 8\n",
      "Epoch: 1 | train_loss: 0.3363 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 16.764 seconds\n",
      "Fold 9\n",
      "Epoch: 1 | train_loss: 0.3392 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 16.792 seconds\n",
      "Fold 10\n",
      "Epoch: 1 | train_loss: 0.3400 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 2 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 3 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 4 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 5 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 6 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 7 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 8 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 9 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Epoch: 10 | train_loss: 0.3133 | train_acc: 1.0000 | val_loss: 0.3133 | val_acc: 1.0000 |\n",
      "Total training time: 17.229 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "batch_size = 32\n",
    "NUM_EPOCHS = 10\n",
    "foldperf={}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "    model = CNN(1024).to(device)\n",
    "    #weight = torch.FloatTensor([1.0,23.0])\n",
    "    #weight = torch.FloatTensor([total_duration_seizure/total_duration, total_duration_nonseizure/total_duration])\n",
    "    weight = torch.FloatTensor([1/total_duration_nonseizure, 1/total_duration_seizure])\n",
    "    #weight = weight.type(torch.LongTensor)\n",
    "    weight = weight.to(device)\n",
    "    # Setup loss function and optimizer\n",
    "    #loss_fn = nn.BCELoss(weight = weight)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight = weight)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "    #, betas=(0.9, 0.999))\n",
    "\n",
    "    # Start the timer\n",
    "    from timeit import default_timer as timer \n",
    "    start_time = timer()\n",
    "\n",
    "    # Train model_0 \n",
    "    model_results = train(model=model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "    end_time = timer()\n",
    "    print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "    foldperf['fold{}'.format(fold+1)] = model_results  \n",
    "\n",
    "torch.save(model,'k_cross_CNN2D_4_5.pt')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset=test_dataset, # use custom created test Dataset\n",
    "                                    #sampler = sampler,\n",
    "                                    batch_size=32, \n",
    "                                    num_workers=4, \n",
    "                                    shuffle=False)\n",
    "\n",
    "test_loss, test_acc, test_spec = val_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "print(\n",
    "      f\"test_loss: {test_loss:.4f} | \"\n",
    "      f\"test_acc: {test_acc:.4f} | \"\n",
    "      f\"test_spec: {test_spec:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "'''\n",
    "TP : the number of segments that are correctly identified as ictal (x_true == x_pred == 1)\n",
    "TN : the number of EEG segments that are correctly classified as non-ictal (x_true == x_pred == 0)\n",
    "FP : the number of EEG segments that are incorrectly classified as ictal (x_true == 0 && x_pred == 1)\n",
    "FN : the segments that are incorrectly classified as non-ictal (x_true == 1 && x_pred == 0)\n",
    "'''\n",
    "def classificationPerformanceIndexes (true_arr, pred_arr):\n",
    "    (tn, fp, fn, tp) = confusion_matrix(true_arr, pred_arr).ravel()\n",
    "    acc = accuracy_score(true_arr, pred_arr)                           # Accuracy\n",
    "    snv = tp/(tp + fn)                                                 # Sensitivity or True Positive Rate (TPR)\n",
    "    spc = tn/(tn + fp)                                                 # Specificity or True Negative Rate (TNR)\n",
    "    ppv = tp/(tp + fp)                                                 # Precision or Positive Predictive Value (PPV)\n",
    "    f1 = f1_score(true_arr, pred_arr)                                  # F1 score\n",
    "    #mcc = matthews_corrcoef(true_arr, pred_arr)                        # Matthews Correlation Coefficient\n",
    "    #kappa = cohen_kappa_score(true_arr, pred_arr)                      # Cohens Kappa    \n",
    "    return acc, snv, spc, ppv, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassificationPerformanceIndexes(acc, snv, spc, ppv, f1):\n",
    "    #print('Method:', method)\n",
    "    print('Accuracy:', acc)\n",
    "    print('Sensitivity/Recall:', snv)\n",
    "    print('Specificity:', spc)\n",
    "    print('Precision:', ppv)\n",
    "    print('F1 Score:', f1)\n",
    "    #print('Matthews Correlation Coefficient:', mcc)\n",
    "    #print('Cohens Kappa:', kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, snv, spc, ppv, f1 = classificationPerformanceIndexes(y_true, y_pred)\n",
    "printClassificationPerformanceIndexes(acc, snv, spc, ppv, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_curves(results):\n",
    "  #: Dict[str, List[float]]\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and test)\n",
    "    losses = results['train_loss']\n",
    "    losses_array= [loss for loss in losses]\n",
    "    #loss.detach().numpy()\n",
    "    #print(losses)\n",
    "    val_losses = results['val_loss']\n",
    "    #val_losses_array= [loss.detach().numpy() for loss in val_losses]\n",
    "    val_losses_array= [loss for loss in val_losses]\n",
    "\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    accuracy = results['train_acc']\n",
    "    #print(accuracy)\n",
    "    val_accuracy = results['val_acc']\n",
    "\n",
    "    # Get the specificity of the results dictionary (training and test)\n",
    "    specificity = results['train_spec']\n",
    "    specificity_array= [spec.cpu().numpy() for spec in specificity]\n",
    "    #print(specificity_array)\n",
    "    val_specificity = results['val_spec']\n",
    "    val_specificity_array = [spec.cpu().numpy() for spec in val_specificity]\n",
    "    #val_specificity_array = [spec for spec in val_specificity]\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "    #print(type(epochs))\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, losses_array, label='train_loss')\n",
    "    plt.plot(epochs, val_losses_array, label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot specificity\n",
    "    # plt.subplot(1, 3, 3)\n",
    "    # plt.plot(epochs, specificity_array, label='train_specificity')\n",
    "    # plt.plot(epochs, val_specificity_array, label='val_specificity')\n",
    "    # plt.title('Specificity')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.legend()\n",
    "\n",
    "plot_loss_curves(model_results)\n",
    "plt.savefig('model_results_with_class_weights_1_2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model = CNN(1024).to(device)\n",
    "weight = torch.FloatTensor([1.0,23.0])\n",
    "#weight = weight.type(torch.LongTensor)\n",
    "weight = weight.to(device)\n",
    "# Setup loss function and optimizer\n",
    "#loss_fn = nn.BCELoss(weight = weight)\n",
    "loss_fn = nn.CrossEntropyLoss(weight = weight)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "#, betas=(0.9, 0.999))\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0 \n",
    "model_results = train(model=model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "358db552dfe214f2c48020eb7daba081d1eb143fc51d32ee7a11605d9b3ad321"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
